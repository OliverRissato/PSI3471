{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    sig = 1 / (1 + math.exp(x))\n",
    "    return sig\n",
    "\n",
    "def sigmoid_derivate(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "\n",
    "    def __init__(self, L):\n",
    "        self.Nl = len(L)\n",
    "        self.L = L\n",
    "        self.b = [np.random.randn(y,1) for y in L[1:]]\n",
    "        self.w = [np.random.randn(y,x) for x, y in zip(L[:-1], L[1:])]\n",
    "\n",
    "    def feedfoward(self, a):\n",
    "        a = sigmoid(np.dot(self.w, a) + self.b)\n",
    "        return a\n",
    "\n",
    "    def training(self, Xd, Ne, Nb, eta, Xd_test=None):\n",
    "        Xd = list(Xd)\n",
    "        n = len(Xd)\n",
    "\n",
    "        if Xd_test:\n",
    "            Xd_test = list(Xd_test)\n",
    "            n_test = len(Xd_test)\n",
    "\n",
    "        for j in range(Ne):\n",
    "            random.shuffle(Xd)\n",
    "\n",
    "            mini_batches = [Xd[k:k+Nb] for k in range(0, n, Nb)]\n",
    "            \n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_perceptrons(mini_batch, eta)\n",
    "\n",
    "            if Xd_test:\n",
    "                print(\"Época {} finalizada: {} / {}\".format(j,self.test(Xd_test), n_test))\n",
    "            else:\n",
    "                print(\"Época {} finalizada\".format(j))\n",
    "\n",
    "\n",
    "    \n",
    "    def update_perceptrons(self, Xd, eta):\n",
    "        grad_b = [np.zeros(b.shape) for b in self.b]\n",
    "        grad_w = [np.zeros(w.shape) for w in self.w]\n",
    "\n",
    "        for x, y in Xd:\n",
    "            del_grad_b, del_grad_w = self.backpropagation(x, y)\n",
    "\n",
    "            grad_b = [nb + dnb for nb,dnb in zip(grad_b, del_grad_b)]\n",
    "            grad_w = [nw + dnw for nw,dnw in zip(grad_w, del_grad_w)]\n",
    "\n",
    "        self.w = [w - (eta/len(Xd))*nw for w,nw in zip(self.w, grad_w)]\n",
    "        self.b = [b - (eta/len(Xd))*nb for b,nb in zip(self.b, grad_b)]\n",
    "\n",
    "    def backpropagation(self, x, y):\n",
    "        grad_b = [np.zeros(b.shape) for b in self.b]\n",
    "        grad_w = [np.zeros(w.shape) for w in self.w]\n",
    "\n",
    "        activation = x\n",
    "\n",
    "        activations = [x]\n",
    "\n",
    "        zs = []\n",
    "\n",
    "        for b, w in zip(self.b, self.w):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        \n",
    "        delta = (activations[-1]-y) * sigmoid_derivate(zs[-1])\n",
    "        grad_b[-1] = delta\n",
    "        grad_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        \n",
    "        for l in range(2, self.Nl):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_derivate(z)\n",
    "            delta = np.dot(self.w[-l+1].transpose(), delta) * sp\n",
    "            grad_b[-l] = delta\n",
    "            grad_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (grad_b, grad_w)\n",
    "\n",
    "    def test(self, Xd_test):\n",
    "        result = [(np.argmax(self.feedfoward(x)), y) for (x, y) in Xd_test]\n",
    "        return sum(int( x == y) for (x, y) in Xd_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rede1 = MLP([3,2,1])\n",
    "\n",
    "data_df = pd.read_csv(\"circles_and_squares.csv\")\n",
    "data_df_treino = data_df.iloc[0:800, :]\n",
    "data_df_test = data_df.iloc[800:, :]\n",
    "\n",
    "gabarito = data_df_test[\"400\"]\n",
    "gabarito = gabarito.to_numpy()\n",
    "data_df_test = data_df_test.drop(columns=['400'])\n",
    "\n",
    "Xd_test = data_df_test.to_numpy()\n",
    "\n",
    "reference = data_df_treino[\"400\"]\n",
    "reference = reference.to_numpy()\n",
    "data = data_df_treino.drop(columns=[\"400\"])\n",
    "\n",
    "Xd = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Oliver\\Documents\\Poli\\PSI3471\\PSI3471\\Lição_de_Casa\\Lição_de_Casa_5\\neural_net.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Oliver/Documents/Poli/PSI3471/PSI3471/Li%C3%A7%C3%A3o_de_Casa/Li%C3%A7%C3%A3o_de_Casa_5/neural_net.ipynb#ch0000007?line=0'>1</a>\u001b[0m rede1\u001b[39m.\u001b[39;49mtraining((Xd, reference), \u001b[39m50\u001b[39;49m, \u001b[39m100\u001b[39;49m, \u001b[39m0.01\u001b[39;49m,(Xd_test, gabarito))\n",
      "\u001b[1;32mc:\\Users\\Oliver\\Documents\\Poli\\PSI3471\\PSI3471\\Lição_de_Casa\\Lição_de_Casa_5\\neural_net.ipynb Cell 3'\u001b[0m in \u001b[0;36mMLP.training\u001b[1;34m(self, Xd, Ne, Nb, eta, Xd_test)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Oliver/Documents/Poli/PSI3471/PSI3471/Li%C3%A7%C3%A3o_de_Casa/Li%C3%A7%C3%A3o_de_Casa_5/neural_net.ipynb#ch0000002?line=23'>24</a>\u001b[0m mini_batches \u001b[39m=\u001b[39m [Xd[k:k\u001b[39m+\u001b[39mNb] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, n, Nb)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Oliver/Documents/Poli/PSI3471/PSI3471/Li%C3%A7%C3%A3o_de_Casa/Li%C3%A7%C3%A3o_de_Casa_5/neural_net.ipynb#ch0000002?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m mini_batch \u001b[39min\u001b[39;00m mini_batches:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Oliver/Documents/Poli/PSI3471/PSI3471/Li%C3%A7%C3%A3o_de_Casa/Li%C3%A7%C3%A3o_de_Casa_5/neural_net.ipynb#ch0000002?line=26'>27</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_perceptrons(mini_batch, eta)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Oliver/Documents/Poli/PSI3471/PSI3471/Li%C3%A7%C3%A3o_de_Casa/Li%C3%A7%C3%A3o_de_Casa_5/neural_net.ipynb#ch0000002?line=28'>29</a>\u001b[0m \u001b[39mif\u001b[39;00m Xd_test:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Oliver/Documents/Poli/PSI3471/PSI3471/Li%C3%A7%C3%A3o_de_Casa/Li%C3%A7%C3%A3o_de_Casa_5/neural_net.ipynb#ch0000002?line=29'>30</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mÉpoca \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m finalizada: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(j,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest(Xd_test), n_test))\n",
      "\u001b[1;32mc:\\Users\\Oliver\\Documents\\Poli\\PSI3471\\PSI3471\\Lição_de_Casa\\Lição_de_Casa_5\\neural_net.ipynb Cell 3'\u001b[0m in \u001b[0;36mMLP.update_perceptrons\u001b[1;34m(self, Xd, eta)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Oliver/Documents/Poli/PSI3471/PSI3471/Li%C3%A7%C3%A3o_de_Casa/Li%C3%A7%C3%A3o_de_Casa_5/neural_net.ipynb#ch0000002?line=36'>37</a>\u001b[0m grad_b \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mzeros(b\u001b[39m.\u001b[39mshape) \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Oliver/Documents/Poli/PSI3471/PSI3471/Li%C3%A7%C3%A3o_de_Casa/Li%C3%A7%C3%A3o_de_Casa_5/neural_net.ipynb#ch0000002?line=37'>38</a>\u001b[0m grad_w \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mzeros(w\u001b[39m.\u001b[39mshape) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Oliver/Documents/Poli/PSI3471/PSI3471/Li%C3%A7%C3%A3o_de_Casa/Li%C3%A7%C3%A3o_de_Casa_5/neural_net.ipynb#ch0000002?line=39'>40</a>\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m Xd:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Oliver/Documents/Poli/PSI3471/PSI3471/Li%C3%A7%C3%A3o_de_Casa/Li%C3%A7%C3%A3o_de_Casa_5/neural_net.ipynb#ch0000002?line=40'>41</a>\u001b[0m     del_grad_b, del_grad_w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackpropagation(x, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Oliver/Documents/Poli/PSI3471/PSI3471/Li%C3%A7%C3%A3o_de_Casa/Li%C3%A7%C3%A3o_de_Casa_5/neural_net.ipynb#ch0000002?line=42'>43</a>\u001b[0m     grad_b \u001b[39m=\u001b[39m [nb \u001b[39m+\u001b[39m dnb \u001b[39mfor\u001b[39;00m nb,dnb \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(grad_b, del_grad_b)]\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "rede1.training((Xd, reference), 50, 100, 0.01,(Xd_test, gabarito))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "71963e98eadabb68e8978a13f70499e318779c31367c0bef81974228087b6def"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
